# topic 1
|word       |    weight|
|:----------|---------:|
|workers    | 0.0209664|
|labels     | 0.0206154|
|tasks      | 0.0157840|
|label      | 0.0138745|
|stage      | 0.0127411|
|correction | 0.0109847|
|self       | 0.0108933|
|answer     | 0.0090024|
|answers    | 0.0087473|
|question   | 0.0084522|


|key           |    weight|title                                                                           |
|:-------------|---------:|:-------------------------------------------------------------------------------|
|shaha16       | 0.9996694|No Oops, You Won’t Do It Again: Mechanisms for Self-correction in Crowdsourcing |
|ustinovskiy16 | 0.9996336|Meta–Gradient Boosted Decision Tree Model for Weight and Target Learning        |
|ok16          | 0.7572863|Optimality of Belief Propagation for Crowdsourced Classification                |
|gaoa16        | 0.4221341|Exact Exponent in Optimal Rates for Crowdsourcing                               |
|zaremba16     | 0.1877589|Learning Simple Algorithms from Examples                                        |


# topic 2
|word          |    weight|
|:-------------|---------:|
|images        | 0.0308343|
|image         | 0.0287936|
|softmax       | 0.0256920|
|text          | 0.0163913|
|network       | 0.0144397|
|tasks         | 0.0140720|
|transfer      | 0.0106519|
|visual        | 0.0102142|
|convolutional | 0.0094018|
|deep          | 0.0089858|


|key       |    weight|title                                                                    |
|:---------|---------:|:------------------------------------------------------------------------|
|reed16    | 0.9932230|Generative Adversarial Text to Image Synthesis                           |
|larsen16  | 0.9589336|Autoencoding beyond pixels using a learned similarity metric             |
|liud16    | 0.9300475|Large-Margin Softmax Loss for Convolutional Neural Networks              |
|ulyanov16 | 0.8945046|Texture Networks: Feed-forward Synthesis of Textures and Stylized Images |
|leeb16    | 0.8311740|Asymmetric Multi-task Learning Based on Task Relatedness and Loss        |


# topic 3
|word        |    weight|
|:-----------|---------:|
|speech      | 0.0189772|
|recurrent   | 0.0168949|
|noise       | 0.0146589|
|memory      | 0.0125028|
|deep        | 0.0118672|
|recognition | 0.0104713|
|network     | 0.0104118|
|activation  | 0.0098958|
|noisy       | 0.0092220|
|lstm        | 0.0085169|


|key        |    weight|title                                                                 |
|:----------|---------:|:---------------------------------------------------------------------|
|gulcehre16 | 0.9996762|Noisy Activation Functions                                            |
|hwanga16   | 0.9564370|Sequence to Sequence Training of CTC-RNNs with Partial Windowing      |
|amodei16   | 0.8865656|Deep Speech 2 : End-to-End Speech Recognition in English and Mandarin |
|arjovsky16 | 0.7855090|Unitary Evolution Recurrent Neural Networks                           |
|henaff16   | 0.7549049|Recurrent Orthogonal Networks and Long-Memory Tasks                   |


# topic 4
|word          |    weight|
|:-------------|---------:|
|pose          | 0.0308867|
|pooling       | 0.0230426|
|layers        | 0.0227821|
|convolutional | 0.0185317|
|deep          | 0.0148008|
|layer         | 0.0147572|
|network       | 0.0141724|
|object        | 0.0140690|
|images        | 0.0095391|
|depth         | 0.0094023|


|key         |    weight|title                                                                                                        |
|:-----------|---------:|:------------------------------------------------------------------------------------------------------------|
|elhoseiny16 | 0.9997483|A Comparative Analysis and Study of Multiview CNN Models for Joint Object Categorization and Pose Estimation |
|cohenb16    | 0.9997389|Convolutional Rectifier Networks as Generalized Tensor Decompositions                                        |
|wiatowski16 | 0.9996398|Discrete Deep Feature Extraction: A Theory and New Architectures                                             |
|dieleman16  | 0.5514161|Exploiting Cyclic Symmetry in Convolutional Neural Networks                                                  |
|almahairi16 | 0.4866945|Dynamic Capacity Networks                                                                                    |


# topic 5
|word       |    weight|
|:----------|---------:|
|human      | 0.0236230|
|ridge      | 0.0188943|
|active     | 0.0169747|
|principal  | 0.0159007|
|label      | 0.0147726|
|regression | 0.0141512|
|strongly   | 0.0135386|
|items      | 0.0133918|
|mixed      | 0.0131450|
|type       | 0.0128646|


|key        |    weight|title                                                               |
|:----------|---------:|:-------------------------------------------------------------------|
|suh16      | 0.9996596|The Label Complexity of Mixed-Initiative Classifier Training        |
|balduzzi16 | 0.7833655|Strongly-Typed Recurrent Neural Networks                            |
|frostig16  | 0.7509212|Principal Component Projection Without Principal Component Analysis |
|NA         |        NA|NA                                                                  |
|NA         |        NA|NA                                                                  |


# topic 6
|word          |    weight|
|:-------------|---------:|
|clustering    | 0.0865897|
|cluster       | 0.0518668|
|clusters      | 0.0206752|
|distributed   | 0.0133794|
|clus          | 0.0097559|
|communication | 0.0091085|
|tree          | 0.0082236|
|ratio         | 0.0073387|
|edges         | 0.0072595|
|discrete      | 0.0072464|


|key     |    weight|title                                                                   |
|:-------|---------:|:-----------------------------------------------------------------------|
|chenc16 | 0.9706449|Clustering High Dimensional Categorical Data via Topographical Features |
|puleo16 | 0.9292727|Correlation Clustering and Biclustering with Locally Bounded Errors     |
|ding16  | 0.8906525|\(K\)-Means Clustering with Distributed Dimensions                      |
|xieb16  | 0.5017118|Unsupervised Deep Embedding for Clustering Analysis                     |
|korda16 | 0.3591545|Distributed Clustering of Linear Bandits in Peer to Peer Networks       |


# topic 7
|word        |    weight|
|:-----------|---------:|
|dual        | 0.0235058|
|strongly    | 0.0185286|
|coordinate  | 0.0164093|
|descent     | 0.0160150|
|primal      | 0.0144938|
|safe        | 0.0138254|
|zhang       | 0.0138088|
|shalev      | 0.0115598|
|shwartz     | 0.0115426|
|accelerated | 0.0109480|


|key               |    weight|title                                                                         |
|:-----------------|---------:|:-----------------------------------------------------------------------------|
|shibagaki16       | 0.9995863|Simultaneous Safe Screening of Features and Samples in Doubly Sparse Modeling |
|allen-zhuc16      | 0.9995695|Even Faster Accelerated Coordinate Descent Using Non-Uniform Sampling         |
|dunner16          | 0.9819995|Primal-Dual Rates and Certificates                                            |
|qua16             | 0.8792893|Fast Rate Analysis of Some Stochastic Optimization Algorithms                 |
|shalev-shwartza16 | 0.8599416|SDCA without Duality, Regularization, and Individual Convexity                |


# topic 8
|word         |    weight|
|:------------|---------:|
|eigenvector  | 0.0107070|
|power        | 0.0098529|
|runtime      | 0.0091429|
|lemma        | 0.0090012|
|bias         | 0.0078777|
|global       | 0.0070933|
|minimization | 0.0070464|
|initial      | 0.0069860|
|direct       | 0.0068311|
|hinge        | 0.0064245|


|key       |    weight|title                                                                            |
|:---------|---------:|:--------------------------------------------------------------------------------|
|shamirb16 | 0.9430553|Convergence of Stochastic Gradient Descent for PCA                               |
|safran16  | 0.8078732|On the Quality of the Initial Basin in Overspecified Neural Networks             |
|shamira16 | 0.7547022|Fast Stochastic Algorithms for SVD and PCA: Convergence Properties and Convexity |
|nock16    | 0.6280927|k-variates++: more pluses in the k-means++                                       |
|garber16  | 0.6235019|Faster Eigenvector Computation via Shift-and-Invert Preconditioning              |


# topic 9
|word      |    weight|
|:---------|---------:|
|label     | 0.0277249|
|labels    | 0.0209431|
|losses    | 0.0148804|
|threshold | 0.0146111|
|target    | 0.0122289|
|logistic  | 0.0119842|
|dimension | 0.0116718|
|extreme   | 0.0108878|
|sparse    | 0.0103934|
|decision  | 0.0102618|


|key         |    weight|title                                                                                                    |
|:-----------|---------:|:--------------------------------------------------------------------------------------------------------|
|jasinska16  | 0.9996525|Extreme F-measure Maximization using Sparse Probability Estimates                                        |
|yoon16      | 0.9996339|ForecastICU: A Prognostic Decision Support System for Timely Prediction of Intensive Care Unit Admission |
|liua16      | 0.9126121|The Teaching Dimension of Linear Learners                                                                |
|natarajan16 | 0.7083877|Optimal Classification with Multivariate Losses                                                          |
|yenb16      | 0.3604882|PD-Sparse : A Primal and Dual Sparse Approach to Extreme Multiclass and Multilabel Classification        |


# topic 10
|word        |    weight|
|:-----------|---------:|
|distance    | 0.0197795|
|metric      | 0.0131062|
|mixture     | 0.0111195|
|condition   | 0.0102426|
|topic       | 0.0089729|
|rank        | 0.0080106|
|lemma       | 0.0073371|
|spaces      | 0.0063583|
|aggregation | 0.0061591|
|geometric   | 0.0060912|


|key                |    weight|title                                                                  |
|:------------------|---------:|:----------------------------------------------------------------------|
|zhaob16            | 0.9994718|Learning Mixtures of Plackett-Luce Models                              |
|korba16            | 0.9970205|Controlling the distance to a Kemeny consensus without computing it    |
|papakonstantinou16 | 0.9568631|On the Power and Limits of Distance-Based Learning                     |
|arorab16           | 0.8511985|Provable Algorithms for Inference in Topic Models                      |
|glaude16           | 0.7589439|PAC learning of Probabilistic Automaton based on the Method of Moments |


# topic 11
|word          |    weight|
|:-------------|---------:|
|policy        | 0.0255960|
|smooth        | 0.0177321|
|noise         | 0.0121263|
|expert        | 0.0071708|
|weight        | 0.0071671|
|weights       | 0.0070176|
|weighted      | 0.0068233|
|lemma         | 0.0067429|
|prediction    | 0.0060383|
|deterministic | 0.0059705|


|key        |    weight|title                                                                              |
|:----------|---------:|:----------------------------------------------------------------------------------|
|le16       | 0.9995345|Smooth Imitation Learning for Online Sequence Prediction                           |
|la16       | 0.8748499|Cumulative Prospect Theory Meets Reinforcement Learning: Prediction and Control    |
|lii16      | 0.7757109|Recovery guarantee of weighted low-rank approximation via alternating minimization |
|balle16    | 0.7422574|Differentially Private Policy Evaluation                                           |
|couillet16 | 0.5266477|A Random Matrix Approach to Echo-State Neural Networks                             |


# topic 12
|word       |    weight|
|:----------|---------:|
|supervised | 0.0245333|
|embeddings | 0.0219607|
|lstm       | 0.0213358|
|semi       | 0.0185065|
|deep       | 0.0163400|
|embedding  | 0.0152707|
|prediction | 0.0129696|
|unlabeled  | 0.0107204|
|layer      | 0.0106609|
|labeled    | 0.0098493|


|key       |    weight|title                                                                               |
|:---------|---------:|:-----------------------------------------------------------------------------------|
|johnson16 | 0.9997029|Supervised and Semi-Supervised Text Categorization using LSTM for Region Embeddings |
|songa16   | 0.8574824|Factored Temporal Sigmoid Belief Networks for Sequence Learning                     |
|lerer16   | 0.8533121|Learning Physical Intuition of Block Towers by Example                              |
|yanga16   | 0.7045910|Revisiting Semi-Supervised Learning with Graph Embeddings                           |
|maaloe16  | 0.5974780|Auxiliary Deep Generative Models                                                    |


# topic 13
|word          |    weight|
|:-------------|---------:|
|policy        | 0.0439689|
|agent         | 0.0205252|
|action        | 0.0174793|
|reward        | 0.0173532|
|reinforcement | 0.0155160|
|states        | 0.0122418|
|evaluation    | 0.0108792|
|estimator     | 0.0094674|
|agents        | 0.0092608|
|game          | 0.0091176|


|key      |    weight|title                                                                                            |
|:--------|---------:|:------------------------------------------------------------------------------------------------|
|simsek16 | 0.9667894|Why Most Decisions Are Easy in Tetris—And Perhaps in Other Sequential Decision Problems, As Well |
|hoiles16 | 0.9479825|Bounded Off-Policy Evaluation with Missing Data for Course Recommendation and Curriculum Design  |
|abel16   | 0.8890833|Near Optimal Behavior via Approximate State Abstraction                                          |
|jiang16  | 0.8405775|Doubly Robust Off-policy Value Evaluation for Reinforcement Learning                             |
|he16     | 0.8150261|Opponent Modeling in Deep Reinforcement Learning                                                 |


# topic 14
|word          |    weight|
|:-------------|---------:|
|dictionary    | 0.0146124|
|manifold      | 0.0131113|
|sparse        | 0.0112940|
|online        | 0.0097021|
|descent       | 0.0088235|
|matrices      | 0.0087270|
|block         | 0.0081063|
|relaxations   | 0.0075549|
|decomposition | 0.0072206|
|constraints   | 0.0068902|


|key      |    weight|title                                                                                                                              |
|:--------|---------:|:----------------------------------------------------------------------------------------------------------------------------------|
|xub16    | 0.9880430|Matrix Eigen-decomposition via Doubly Stochastic Riemannian Optimization                                                           |
|wangc16  | 0.9748797|On the Statistical Limits of Convex Relaxations                                                                                    |
|mensch16 | 0.9179431|Dictionary Learning for Massive Matrix Factorization                                                                               |
|liue16   | 0.6366716|Quadratic Optimization with Orthogonality Constraints: Explicit Lojasiewicz Exponent and Linear Convergence of Line-Search Methods |
|grosse16 | 0.5390410|A Kronecker-factored approximate Fisher matrix for convolution layers                                                              |


# topic 15
|word          |    weight|
|:-------------|---------:|
|memory        | 0.0391155|
|lstm          | 0.0186912|
|tasks         | 0.0157229|
|network       | 0.0154658|
|video         | 0.0123761|
|rank          | 0.0113987|
|architectures | 0.0108697|
|pooling       | 0.0106202|
|temporal      | 0.0084087|
|maps          | 0.0079680|


|key         |    weight|title                                                         |
|:-----------|---------:|:-------------------------------------------------------------|
|fernando16  | 0.9996600|Learning End-to-end Video Classification with Rank-Pooling    |
|santoro16   | 0.9996457|Meta-Learning with Memory-Augmented Neural Networks           |
|oh16        | 0.8953485|Control of Memory, Active Perception, and Action in Minecraft |
|danihelka16 | 0.8400650|Associative Long Short-Term Memory                            |
|zaremba16   | 0.4545434|Learning Simple Algorithms from Examples                      |


# topic 16
|word           |    weight|
|:--------------|---------:|
|regularization | 0.0197250|
|generalization | 0.0179995|
|stability      | 0.0174279|
|risk           | 0.0156979|
|sparsity       | 0.0111464|
|stable         | 0.0084946|
|regularized    | 0.0075298|
|weight         | 0.0074937|
|minimizing     | 0.0073373|
|auto           | 0.0072251|


|key               |    weight|title                                                                     |
|:-----------------|---------:|:-------------------------------------------------------------------------|
|hardt16           | 0.9638252|Train faster, generalize better: Stability of stochastic gradient descent |
|lib16             | 0.7901841|Low-Rank Matrix Approximation with Stability                              |
|shalev-shwartzb16 | 0.7139051|Minimizing the Maximal Loss: How and Why                                  |
|arpita16          | 0.6130921|Why Regularized Auto-Encoders learn Sparse Representation?                |
|daneshmand16      | 0.4113456|Starting Small - Learning with Adaptive Sample Sizes                      |


# topic 17
|word        |    weight|
|:-----------|---------:|
|regret      | 0.0314530|
|bandit      | 0.0289634|
|armed       | 0.0207545|
|bandits     | 0.0155532|
|reward      | 0.0147627|
|confidence  | 0.0137011|
|bubeck      | 0.0123216|
|exploration | 0.0119848|
|rewards     | 0.0089294|
|budget      | 0.0075075|


|key         |    weight|title                                                                            |
|:-----------|---------:|:--------------------------------------------------------------------------------|
|locatelli16 | 0.9995619|An optimal algorithm for the Thresholding Bandit Problem                         |
|rosenski16  | 0.9995497|Multi-Player Bandits – a Musical Chairs Approach                                 |
|degenne16   | 0.9993848|Anytime optimal algorithms in stochastic multi-armed bandits                     |
|david16     | 0.9865966|PAC Lower Bounds and Efficient Algorithms for The Max \(K\)-Armed Bandit Problem |
|wu16        | 0.9633112|Conservative Bandits                                                             |


# topic 18
|word          |    weight|
|:-------------|---------:|
|policy        | 0.0483203|
|tasks         | 0.0194926|
|reinforcement | 0.0185257|
|control       | 0.0172370|
|learned       | 0.0113026|
|deep          | 0.0112925|
|dynamics      | 0.0106064|
|continuous    | 0.0104843|
|policies      | 0.0100917|
|action        | 0.0100108|


|key      |    weight|title                                                                      |
|:--------|---------:|:--------------------------------------------------------------------------|
|gu16     | 0.9997001|Continuous Deep Q-Learning with Model-based Acceleration                   |
|akrour16 | 0.9996200|Model-Free Trajectory Optimization for Reinforcement Learning              |
|finn16   | 0.9875489|Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization |
|duan16   | 0.8018127|Benchmarking Deep Reinforcement Learning for Continuous Control            |
|ho16     | 0.6015406|Model-Free Imitation Learning with Policy Optimization                     |


# topic 19
|word        |    weight|
|:-----------|---------:|
|kernel      | 0.1172084|
|kernels     | 0.0204356|
|rkhs        | 0.0146940|
|regression  | 0.0115495|
|embedding   | 0.0104214|
|prediction  | 0.0087811|
|hilbert     | 0.0070689|
|machines    | 0.0064398|
|summary     | 0.0062591|
|conditional | 0.0060106|


|key        |    weight|title                                                                              |
|:----------|---------:|:----------------------------------------------------------------------------------|
|kusano16   | 0.9995570|Persistence weighted Gaussian kernel for topological data analysis                 |
|si16       | 0.9994890|Computationally Efficient Nyström Approximation using Fast Transforms              |
|cutajar16  | 0.8315701|Preconditioning Kernel Matrices                                                    |
|mitrovic16 | 0.6580399|DR-ABC: Approximate Bayesian Computation with Kernel-Based Distribution Regression |
|daib16     | 0.5461753|Discriminative Embeddings of Latent Variable Models for Structured Data            |


# topic 20
|word      |    weight|
|:---------|---------:|
|nearest   | 0.0136324|
|event     | 0.0120703|
|distance  | 0.0105179|
|early     | 0.0077598|
|detection | 0.0075897|
|block     | 0.0072727|
|query     | 0.0068438|
|distances | 0.0058413|
|mutual    | 0.0054963|
|remainder | 0.0053694|


|key        |    weight|title                                                                      |
|:----------|---------:|:--------------------------------------------------------------------------|
|lic16      | 0.9996664|Fast k-Nearest Neighbour Search via Dynamic Continuous Indexing            |
|sangnier16 | 0.9867270|Early and Reliable Event Detection Using Proximity Space Representation    |
|newling16  | 0.9085634|Fast k-means with accurate bounds                                          |
|bottesch16 | 0.8394813|Speeding up k-means by approximating Euclidean distances via block vectors |
|steeg16    | 0.6583284|The Information Sieve                                                      |


# topic 21
|word          |    weight|
|:-------------|---------:|
|rank          | 0.0550704|
|matrices      | 0.0324360|
|tensor        | 0.0217797|
|decomposition | 0.0133721|
|spectral      | 0.0128444|
|robust        | 0.0077841|
|subspace      | 0.0070707|
|noise         | 0.0070389|
|eigenvalues   | 0.0067210|
|singular      | 0.0067069|


|key       |    weight|title                                                                             |
|:---------|---------:|:---------------------------------------------------------------------------------|
|ubaru16   | 0.9619952|Fast methods for estimating the Numerical rank of large matrices                  |
|khetan16  | 0.8352567|Data-driven Rank Breaking for Efficient Rank Aggregation                          |
|colombo16 | 0.7612244|Tensor Decomposition via Joint Matrix Schur Decomposition                         |
|tu16      | 0.7435386|Low-rank Solutions of Linear Matrix Equations via Procrustes Flow                 |
|zhange16  | 0.6493604|Provable Non-convex Phase Retrieval with Outliers: Median TruncatedWirtinger Flow |


# topic 22
|word         |    weight|
|:------------|---------:|
|matrices     | 0.0376283|
|structured   | 0.0188906|
|rank         | 0.0106279|
|private      | 0.0105617|
|risk         | 0.0102284|
|estimator    | 0.0078512|
|singular     | 0.0068144|
|differential | 0.0067480|
|norm         | 0.0066382|
|projection   | 0.0066209|


|key               |    weight|title                                                                               |
|:-----------------|---------:|:-----------------------------------------------------------------------------------|
|kasiviswanathan16 | 0.9781771|Efficient Private Empirical Risk Minimization for High-dimensional Learning         |
|choromanska16     | 0.8617239|Binary embeddings with structured hashed projections                                |
|abernethy16       | 0.8545057|Faster Convex Optimization: Simulated Annealing with an Efficient Universal Barrier |
|choromanski16     | 0.7912328|Recycling Randomness with Structure for Sublinear time Kernel Expansions            |
|gui16             | 0.5473617|Towards Faster Rates and Oracle Property for Low-Rank Matrix Estimation             |


# topic 23
|word           |    weight|
|:--------------|---------:|
|sparse         | 0.0399655|
|norm           | 0.0211939|
|lasso          | 0.0157646|
|nonconvex      | 0.0142509|
|sparsity       | 0.0129835|
|proximal       | 0.0122096|
|group          | 0.0112177|
|regularization | 0.0079216|
|estimator      | 0.0061050|
|direct         | 0.0055227|


|key        |    weight|title                                                                                     |
|:----------|---------:|:-----------------------------------------------------------------------------------------|
|melnyk16   | 0.9995791|Estimating Structured Vector Autoregressive Models                                        |
|wangh16    | 0.9957563|Epigraph projections for fast general convex programming                                  |
|yao16      | 0.9681356|Efficient Learning with a Family of Nonconvex Regularizers by Redistributing Nonconvexity |
|fazayeli16 | 0.8874913|Generalized Direct Change Estimation in Ising Model Structure                             |
|lid16      | 0.6133047|Stochastic Variance Reduced Optimization for Nonconvex Sparse Learning                    |


# topic 24
|word           |    weight|
|:--------------|---------:|
|network        | 0.0459913|
|layer          | 0.0284538|
|deep           | 0.0183698|
|activation     | 0.0178455|
|layers         | 0.0159212|
|image          | 0.0119574|
|relu           | 0.0116533|
|convolutional  | 0.0111554|
|reconstruction | 0.0107352|
|width          | 0.0104589|


|key      |    weight|title                                                                                                   |
|:--------|---------:|:-------------------------------------------------------------------------------------------------------|
|wei16    | 0.9909980|Network Morphism                                                                                        |
|xiec16   | 0.9656342|A Theory of Generative ConvNet                                                                          |
|shang16  | 0.9627686|Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units       |
|zhangc16 | 0.9160656|Augmenting Supervised Neural Networks with Unsupervised Objectives for Large-scale Image Classification |
|zhangd16 | 0.5631973|L1-regularized Neural Networks are Improperly Learnable in Polynomial Time                              |


# topic 25
|word        |    weight|
|:-----------|---------:|
|dropout     | 0.0390353|
|network     | 0.0199206|
|layer       | 0.0163801|
|deep        | 0.0148778|
|uncertainty | 0.0145616|
|bayesian    | 0.0120168|
|variational | 0.0093459|
|posterior   | 0.0082778|
|inference   | 0.0077891|
|layers      | 0.0076102|


|key       |    weight|title                                                                                |
|:---------|---------:|:------------------------------------------------------------------------------------|
|bulo16    | 0.9968256|Dropout distillation                                                                 |
|louizos16 | 0.9814347|Structured and Efficient Variational Deep Learning with Matrix Gaussian Posteriors   |
|gal16     | 0.9750197|Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning |
|bui16     | 0.7385751|Deep Gaussian Processes for Regression using Approximate Expectation Propagation     |
|lan16     | 0.5404417|Dealbreaker: A Nonlinear Latent Variable Model for Educational Data                  |


# topic 26
|word        |    weight|
|:-----------|---------:|
|label       | 0.0437361|
|labels      | 0.0271027|
|conditional | 0.0144146|
|prediction  | 0.0142634|
|deep        | 0.0139329|
|energy      | 0.0132956|
|structured  | 0.0123930|
|inference   | 0.0085861|
|hidden      | 0.0067689|
|classifiers | 0.0065189|


|key        |    weight|title                                                         |
|:----------|---------:|:-------------------------------------------------------------|
|lij16      | 0.9996948|Conditional Bernoulli Mixtures for Multi-label Classification |
|belanger16 | 0.9679269|Structured Prediction Energy Networks                         |
|shaham16   | 0.8529741|A Deep Learning Approach to Unsupervised Ensemble Learning    |
|cisse16    | 0.8112133|ADIOS: Architectures Deep In Output Space                     |
|songb16    | 0.3564005|Training Deep Neural Networks via Direct Loss Minimization    |


# topic 27
|word          |    weight|
|:-------------|---------:|
|gibbs         | 0.0320519|
|markov        | 0.0185572|
|mixing        | 0.0169729|
|sampler       | 0.0161919|
|chain         | 0.0158675|
|monte         | 0.0116938|
|carlo         | 0.0115643|
|mcmc          | 0.0100029|
|bias          | 0.0077613|
|distributions | 0.0070780|


|key         |    weight|title                                                                                         |
|:-----------|---------:|:---------------------------------------------------------------------------------------------|
|rainforth16 | 0.9995446|Interacting Particle Markov Chain Monte Carlo                                                 |
|sa16        | 0.9197006|Ensuring Rapid Mixing and Low Bias for Asynchronous Gibbs Sampling                            |
|carlson16   | 0.8713189|Partition Functions from Rao-Blackwellized Tempered Sampling                                  |
|tosh16      | 0.6902312|Mixing Rates for the Alternating Gibbs Sampler over Restricted Boltzmann Machines and Friends |
|lig16       | 0.6296218|Gaussian quadrature for matrix inverse forms with applications                                |


# topic 28
|word       |    weight|
|:----------|---------:|
|domain     | 0.0336617|
|adaptation | 0.0173060|
|target     | 0.0172115|
|covariance | 0.0148609|
|source     | 0.0137595|
|components | 0.0126263|
|poisson    | 0.0122132|
|domains    | 0.0106625|
|bayesian   | 0.0099319|
|joint      | 0.0088146|


|key             |    weight|title                                                                  |
|:---------------|---------:|:----------------------------------------------------------------------|
|germain16       | 0.9996598|A New PAC-Bayesian Perspective on Domain Adaptation                    |
|pandey16        | 0.9994686|On collapsed representation of hierarchical Completely Random Measures |
|menon16         | 0.9722401|Linking losses for density ratio and class-probability estimation      |
|gong16          | 0.9566867|Domain Adaptation with Conditional Transferable Components             |
|podosinnikova16 | 0.8039802|Beyond CCA: Moment Matching for Multi-View Models                      |


# topic 29
|word        |    weight|
|:-----------|---------:|
|inference   | 0.0165661|
|stability   | 0.0149779|
|variational | 0.0140804|
|predictive  | 0.0133655|
|regression  | 0.0106635|
|noise       | 0.0105025|
|region      | 0.0104612|
|dynamics    | 0.0090605|
|distributed | 0.0086017|
|covariance  | 0.0082431|


|key           |    weight|title                                                                                                         |
|:-------------|---------:|:-------------------------------------------------------------------------------------------------------------|
|vinogradska16 | 0.9996811|Stability of Controllers for Gaussian Process Forward Models                                                  |
|hoang16       | 0.9996784|A Distributed Variational Inference Framework for Unifying Parallel Sparse Gaussian Process Regression Models |
|sun16         | 0.9592775|Learning to Filter with Predictive State Inference Machines                                                   |
|mandt16       | 0.6256976|A Variational Analysis of Stochastic Gradient Algorithms                                                      |
|bonilla16     | 0.6085730|Extended and Unscented Kitchen Sinks                                                                          |


# topic 30
|word         |    weight|
|:------------|---------:|
|greedy       | 0.0360329|
|maximization | 0.0144137|
|constraints  | 0.0127209|
|monotone     | 0.0106641|
|columns      | 0.0098442|
|price        | 0.0087792|
|constraint   | 0.0086806|
|round        | 0.0082903|
|stage        | 0.0082813|
|pair         | 0.0078564|


|key             |    weight|title                                                                               |
|:---------------|---------:|:-----------------------------------------------------------------------------------|
|altschuler16    | 0.9995874|Greedy Column Subset Selection: New Bounds and Distributed Algorithms               |
|lucic16         | 0.9995615|Horizontally Scalable Submodular Maximization                                       |
|balkanski16     | 0.9938367|Learning Sparse Combinatorial Representations via Two-stage Submodular Maximization |
|mirzasoleiman16 | 0.8639112|Fast Constrained Submodular Maximization: Personalized Data Summarization           |
|baib16          | 0.6141004|Algorithms for Optimizing the Ratio of Submodular Functions                         |


# topic 31
|word     |    weight|
|:--------|---------:|
|graph    | 0.0923088|
|graphs   | 0.0391039|
|nodes    | 0.0222579|
|edges    | 0.0157143|
|spectral | 0.0156982|
|edge     | 0.0156147|
|node     | 0.0127512|
|flow     | 0.0122848|
|vertices | 0.0088554|
|recovery | 0.0064924|


|key       |    weight|title                                                             |
|:---------|---------:|:-----------------------------------------------------------------|
|veldt16   | 0.9996774|A Simple and Strongly-Local Flow-Based Method for Cut Improvement |
|chena16   | 0.9371404|Community Recovery in Graphs with Locality                        |
|niepert16 | 0.8443329|Learning Convolutional Neural Networks for Graphs                 |
|weller16  | 0.5548765|Uprooting and Rerooting Graphical Models                          |
|liuf16    | 0.5381023|Cross-Graph Learning of Multi-Relational Associations             |


# topic 32
|word      |    weight|
|:---------|---------:|
|hidden    | 0.0371366|
|layer     | 0.0356646|
|network   | 0.0279968|
|units     | 0.0237946|
|layers    | 0.0183327|
|deep      | 0.0145021|
|threshold | 0.0120454|
|relu      | 0.0118290|
|mnist     | 0.0104559|
|trained   | 0.0080540|


|key              |    weight|title                                                                                    |
|:----------------|---------:|:----------------------------------------------------------------------------------------|
|oord16           | 0.9996687|Pixel Recurrent Neural Networks                                                          |
|panb16           | 0.9996620|Expressiveness of Rectifier Networks                                                     |
|gilad-bachrach16 | 0.7776442|CryptoNets: Applying Neural Networks to Encrypted Data with High Throughput and Accuracy |
|bornschein16     | 0.3921211|Bidirectional Helmholtz Machines                                                         |
|zheng16          | 0.3261444|A Neural Autoregressive Approach to Collaborative Filtering                              |


# topic 33
|word          |    weight|
|:-------------|---------:|
|layer         | 0.0327373|
|layers        | 0.0279549|
|network       | 0.0244216|
|deep          | 0.0225836|
|convolutional | 0.0163335|
|batch         | 0.0139640|
|convolution   | 0.0123424|
|normalization | 0.0118897|
|maps          | 0.0103553|
|relu          | 0.0088548|


|key        |    weight|title                                                                                                    |
|:----------|---------:|:--------------------------------------------------------------------------------------------------------|
|wanga16    | 0.9996923|Analysis of Deep Neural Networks with Extended Data Jacobian Matrix                                      |
|arpitb16   | 0.9996655|Normalization Propagation: A Parametric Technique for Removing Internal Covariate Shift in Deep Networks |
|lia16      | 0.8146976|Multi-Bias Non-linear Activation in Deep Neural Networks                                                 |
|cohenc16   | 0.8028851|Group Equivariant Convolutional Networks                                                                 |
|luketina16 | 0.4848067|Scalable Gradient-Based Tuning of Continuous Regularization Hyperparameters                              |


# topic 34
|word           |    weight|
|:--------------|---------:|
|processes      | 0.0169426|
|events         | 0.0092352|
|power          | 0.0089648|
|event          | 0.0086000|
|similarity     | 0.0081755|
|regression     | 0.0080622|
|impact         | 0.0077075|
|network        | 0.0070146|
|regularization | 0.0068813|
|geometric      | 0.0057877|


|key         |    weight|title                                                                        |
|:-----------|---------:|:----------------------------------------------------------------------------|
|baia16      | 0.8844257|Differential Geometric Regularization for Supervised Learning of Classifiers |
|xuc16       | 0.8676028|Learning Granger Causality for Hawkes Processes                              |
|johansson16 | 0.8150785|Learning Representations for Counterfactual Inference                        |
|wangg16     | 0.7859451|Isotonic Hawkes Processes                                                    |
|dalal16     | 0.6178544|Hierarchical Decision Making In Electricity Grid Management                  |


# topic 35
|word          |    weight|
|:-------------|---------:|
|variational   | 0.0456186|
|latent        | 0.0388917|
|inference     | 0.0377866|
|posterior     | 0.0247527|
|bayesian      | 0.0198193|
|likelihood    | 0.0119409|
|distributions | 0.0085108|
|generative    | 0.0082699|
|hierarchical  | 0.0062528|
|community     | 0.0061327|


|key         |    weight|title                                                                                       |
|:-----------|---------:|:-------------------------------------------------------------------------------------------|
|schein16    | 0.9996810|Bayesian Poisson Tucker Decomposition for Learning the Structure of International Relations |
|xiea16      | 0.9948672|Diversity-Promoting Bayesian Learning of Latent Variable Models                             |
|zhaoa16     | 0.9193953|Collapsed Variational Inference for Sum-Product Networks                                    |
|ranganath16 | 0.9150988|Hierarchical Variational Models                                                             |
|mnihb16     | 0.4869304|Variational Inference for Monte Carlo Objectives                                            |


# topic 36
|word          |    weight|
|:-------------|---------:|
|tree          | 0.0294416|
|distance      | 0.0128390|
|descent       | 0.0127282|
|constraints   | 0.0126637|
|instances     | 0.0086300|
|trees         | 0.0083460|
|node          | 0.0080053|
|leaves        | 0.0077140|
|direction     | 0.0073818|
|distributions | 0.0068241|


|key           |    weight|title                                                                       |
|:-------------|---------:|:---------------------------------------------------------------------------|
|kantchelian16 | 0.9599732|Evasion and Hardening of Tree Ensemble Classifiers                          |
|canevet16     | 0.9358867|Importance Sampling Tree for Large-scale Empirical Expectation              |
|thomasb16     | 0.9213099|Energetic Natural Gradient Descent                                          |
|mussmann16    | 0.7325819|Learning and Inference via Maximum Inner Product Search                     |
|achim16       | 0.6993663|Beyond Parity Constraints: Fourier Analysis of Hash Functions for Inference |


# topic 37
|word            |    weight|
|:---------------|---------:|
|columns         | 0.0305162|
|group           | 0.0202807|
|lasso           | 0.0172793|
|subspace        | 0.0151480|
|column          | 0.0141974|
|selection       | 0.0141710|
|rows            | 0.0125887|
|subspaces       | 0.0091003|
|series          | 0.0086389|
|hyperparameters | 0.0084334|


|key                |    weight|title                                                                           |
|:------------------|---------:|:-------------------------------------------------------------------------------|
|pimentel-alarcon16 | 0.9996625|The Information-Theoretic Requirements of Subspace Clustering with Missing Data |
|bauer16            | 0.9777615|The Arrow of Time in Multivariate Time Series                                   |
|daia16             | 0.9008976|The knockoff filter for FDR control in group-sparse and multitask regression    |
|zhanga16           | 0.8774472|On the Consistency of Feature Selection With Lasso for Non-linear Targets       |
|wange16            | 0.6975971|No penalty no tears: Least squares in high-dimensional linear models            |


# topic 38
|word          |    weight|
|:-------------|---------:|
|factorization | 0.0423200|
|message       | 0.0204150|
|response      | 0.0202530|
|missing       | 0.0200901|
|completion    | 0.0167982|
|passing       | 0.0164454|
|poisson       | 0.0158371|
|minimization  | 0.0132293|
|entries       | 0.0131932|
|sparsity      | 0.0124735|


|key            |    weight|title                                                                 |
|:--------------|---------:|:---------------------------------------------------------------------|
|ravanbakhsha16 | 0.9996625|Boolean Matrix Factorization and Noisy Completion via Message Passing |
|basbug16       | 0.9996326|Hierarchical Compound Poisson Factorization                           |
|baib16         | 0.3616835|Algorithms for Optimizing the Ratio of Submodular Functions           |
|lan16          | 0.2521961|Dealbreaker: A Nonlinear Latent Variable Model for Educational Data   |
|NA             |        NA|NA                                                                    |


# topic 39
|word          |    weight|
|:-------------|---------:|
|regression    | 0.0264631|
|noise         | 0.0199133|
|tensor        | 0.0124630|
|additive      | 0.0123499|
|view          | 0.0094187|
|estimator     | 0.0081669|
|nonlinear     | 0.0077633|
|nonparametric | 0.0077003|
|recovery      | 0.0069241|
|sparse        | 0.0067186|


|key            |    weight|title                                                                              |
|:--------------|---------:|:----------------------------------------------------------------------------------|
|bhowmik16      | 0.9971588|Sparse Parameter Recovery from Aggregated Data                                     |
|kandasamy16    | 0.8143472|Additive Approximations in High Dimensional Nonparametric Regression via the SALSA |
|imaizumi16     | 0.7605610|Doubly Decomposing Nonparametric Tensor Regression                                 |
|michaeli16     | 0.6566064|Nonparametric Canonical Correlation Analysis                                       |
|bhattacharya16 | 0.6229198|Non-negative Matrix Factorization under Heavy Noise                                |


# topic 40
|word           |    weight|
|:--------------|---------:|
|inference      | 0.0200437|
|fourier        | 0.0165265|
|code           | 0.0148102|
|probabilistic  | 0.0125215|
|tree           | 0.0115069|
|graphical      | 0.0096547|
|node           | 0.0086509|
|partition      | 0.0076363|
|domain         | 0.0068326|
|representation | 0.0065573|


|key          |    weight|title                                                                            |
|:------------|---------:|:--------------------------------------------------------------------------------|
|xue16        | 0.9996741|Variable Elimination in the Fourier Domain                                       |
|bielik16     | 0.9996655|PHOG: Probabilistic Model for Code                                               |
|friesen16    | 0.9882381|The Sum-Product Theorem: A Foundation for Learning Tractable Models              |
|yena16       | 0.7831965|A Convex Atomic-Norm Approach to Multiple Sequence Alignment and Motif Discovery |
|piatkowski16 | 0.7319115|Stochastic Discrete Clenshaw-Curtis Quadrature                                   |


# topic 41
|word     |    weight|
|:--------|---------:|
|user     | 0.0260420|
|items    | 0.0250640|
|item     | 0.0224873|
|ranking  | 0.0211359|
|bandits  | 0.0120740|
|ratings  | 0.0120157|
|users    | 0.0116704|
|position | 0.0112644|
|regret   | 0.0110978|
|rating   | 0.0091971|


|key        |    weight|title                                                            |
|:----------|---------:|:----------------------------------------------------------------|
|lif16      | 0.9995790|Contextual Combinatorial Cascading Bandits                       |
|malherbe16 | 0.9995352|A ranking approach to global optimization                        |
|katariya16 | 0.9852186|DCM Bandits: Learning to Rank with Multiple Clicks               |
|schnabel16 | 0.9004133|Recommendations as Treatments: Debiasing Learning and Evaluation |
|zheng16    | 0.4789924|A Neural Autoregressive Approach to Collaborative Filtering      |


# topic 42
|word          |    weight|
|:-------------|---------:|
|graphical     | 0.0233267|
|conditional   | 0.0158680|
|exponential   | 0.0151467|
|likelihood    | 0.0106087|
|risk          | 0.0096793|
|supervised    | 0.0090266|
|distributions | 0.0085075|
|density       | 0.0081233|
|poisson       | 0.0081030|
|joint         | 0.0079996|


|key           |    weight|title                                                                                                                           |
|:-------------|---------:|:-------------------------------------------------------------------------------------------------------------------------------|
|inouye16      | 0.9996509|Square Root Graphical Models: Multivariate Generalizations of Univariate Exponential Families that Permit Positive Dependencies |
|kawakita16    | 0.9624547|Barron and Cover’s Theory in Supervised Learning and its Application to Lasso                                                   |
|liuc16        | 0.8307745|Structure Learning of Partitioned Markov Networks                                                                               |
|raghunathan16 | 0.8252545|Estimation from Indirect Supervision with Linear Moments                                                                        |
|paige16       | 0.4583454|Inference Networks for Sequential Monte Carlo in Graphical Models                                                               |


# topic 43
|word       |    weight|
|:----------|---------:|
|regret     | 0.0634662|
|online     | 0.0306712|
|feedback   | 0.0213279|
|bandit     | 0.0130432|
|learner    | 0.0110929|
|lemma      | 0.0110246|
|contextual | 0.0091503|
|round      | 0.0083366|
|action     | 0.0082895|
|policy     | 0.0076463|


|key         |    weight|title                                                                                                      |
|:-----------|---------:|:----------------------------------------------------------------------------------------------------------|
|syrgkanis16 | 0.9996459|Efficient Algorithms for Adversarial Contextual Learning                                                   |
|yangb16     | 0.9994854|Tracking Slowly Moving Clairvoyant: Optimal Dynamic Regret of Online Learning with True and Noisy Gradient |
|gyorgy16    | 0.8824985|Shifting Regret, Mirror Descent, and Matrices                                                              |
|rakhlin16   | 0.8442777|BISTRO: An Efficient Relaxation-Based Method for Contextual Bandits                                        |
|cohena16    | 0.7922193|Online Learning with Feedback Graphs Without the Graphs                                                    |


# topic 44
|word       |    weight|
|:----------|---------:|
|bayesian   | 0.0191408|
|objectives | 0.0144618|
|posterior  | 0.0093808|
|carlo      | 0.0091657|
|monte      | 0.0091455|
|energy     | 0.0080692|
|dynamics   | 0.0080444|
|expensive  | 0.0071442|
|global     | 0.0071133|
|noise      | 0.0058406|


|key                 |    weight|title                                                                                             |
|:-------------------|---------:|:-------------------------------------------------------------------------------------------------|
|shahc16             | 0.9995525|Pareto Frontier Learning with Expensive Correlated Objectives                                     |
|hernandez-lobatoa16 | 0.9907193|Predictive Entropy Search for Multi-objective Bayesian Optimization                               |
|carr16              | 0.8934288|BASC: Applying Bayesian Optimization to the Search for Global Minima on Potential Energy Surfaces |
|roychowdhury16      | 0.8432944|Robust Monte Carlo Sampling using Riemannian Nosé-Poincaré Hamiltonian Dynamics                   |
|metzen16            | 0.7275327|Minimum Regret Search for Single- and Multi-Task Optimization                                     |


# topic 45
|word        |    weight|
|:-----------|---------:|
|block       | 0.0239889|
|bfgs        | 0.0185759|
|wolfe       | 0.0146992|
|frank       | 0.0143228|
|coordinate  | 0.0137886|
|dual        | 0.0111814|
|network     | 0.0077979|
|descent     | 0.0074753|
|distributed | 0.0066511|
|memory      | 0.0066051|


|key      |    weight|title                                                                   |
|:--------|---------:|:-----------------------------------------------------------------------|
|wangd16  | 0.9996743|Parallel and Distributed Block-Coordinate Frank-Wolfe Algorithms        |
|osokin16 | 0.9996741|Minding the Gaps for Block Frank-Wolfe Optimization of Structured SVMs  |
|gower16  | 0.9201272|Stochastic Block BFGS: Squeezing More Curvature out of Data             |
|curtis16 | 0.7707201|A Self-Correcting Variable-Metric Algorithm for Stochastic Optimization |
|lim16    | 0.5669659|A Box-Constrained Approach for Hard Permutation Problems                |


# topic 46
|word        |    weight|
|:-----------|---------:|
|estimator   | 0.0401912|
|estimators  | 0.0223558|
|median      | 0.0196845|
|noise       | 0.0136925|
|squared     | 0.0111615|
|testing     | 0.0109811|
|tests       | 0.0103567|
|generalized | 0.0087386|
|power       | 0.0086353|
|null        | 0.0084422|


|key           |    weight|title                                                                                           |
|:-------------|---------:|:-----------------------------------------------------------------------------------------------|
|rogers16      | 0.9996129|Differentially Private Chi-Squared Hypothesis Testing: Goodness of Fit and Independence Testing |
|caragiannis16 | 0.9995857|Truthful Univariate Estimators                                                                  |
|lei16         | 0.8915199|Power of Ordered Hypothesis Testing                                                             |
|liub16        | 0.6822264|A Kernelized Stein Discrepancy for Goodness-of-fit Tests                                        |
|shahb16       | 0.6806191|Stochastically Transitive Models for Pairwise Comparisons: Statistical and Computational Issues |


# topic 47
|word           |    weight|
|:--------------|---------:|
|cell           | 0.0214853|
|tree           | 0.0126627|
|generalization | 0.0123355|
|queries        | 0.0105845|
|cells          | 0.0090640|
|decision       | 0.0090551|
|trees          | 0.0079109|
|uniform        | 0.0076576|
|variation      | 0.0075984|
|detection      | 0.0075065|


|key           |    weight|title                                                                                                  |
|:-------------|---------:|:------------------------------------------------------------------------------------------------------|
|guha16        | 0.9996111|Robust Random Cut Forest Based Anomaly Detection on Streams                                            |
|fan16         | 0.9995046|Accurate Robust and Efficient Error Estimation for Decision Trees                                      |
|prabhakaran16 | 0.8497371|Dirichlet Process Mixture Model for Correcting Technical Variation in Single-Cell Gene Expression Data |
|liberty16     | 0.8017965|Stratified Sampling Meets Machine Learning                                                             |
|osband16      | 0.4956072|Generalization and Exploration via Randomized Value Functions                                          |


# topic 48
|word       |    weight|
|:----------|---------:|
|private    | 0.0244288|
|user       | 0.0170030|
|markov     | 0.0137620|
|check      | 0.0133504|
|activity   | 0.0092525|
|classifier | 0.0083325|
|states     | 0.0082518|
|global     | 0.0080684|
|preference | 0.0073345|
|prediction | 0.0071187|


|key       |    weight|title                                                                                                                         |
|:---------|---------:|:-----------------------------------------------------------------------------------------------------------------------------|
|pana16    | 0.9997256|Markov-modulated Marked Poisson Processes for Check-in Data                                                                   |
|hamm16    | 0.9995731|Learning privately from multiparty data                                                                                       |
|saeedi16  | 0.8682737|The Segmented iHMM: A Simple, Efficient Hierarchical Infinite HMM                                                             |
|kairouz16 | 0.8523901|Discrete Distribution Estimation under Local Privacy                                                                          |
|guan16    | 0.5418022|Efficient Multi-Instance Learning for Activity Recognition from Time Series Data Using an Auto-Regressive Hidden Markov Model |


# topic 49
|word       |    weight|
|:----------|---------:|
|attention  | 0.0444607|
|memory     | 0.0266993|
|question   | 0.0203496|
|network    | 0.0144710|
|mechanism  | 0.0125997|
|deep       | 0.0119783|
|answer     | 0.0113638|
|generative | 0.0105477|
|answering  | 0.0091500|
|tasks      | 0.0085714|


|key       |    weight|title                                                                    |
|:---------|---------:|:------------------------------------------------------------------------|
|xiong16   | 0.9996879|Dynamic Memory Networks for Visual and Textual Question Answering        |
|kumar16   | 0.9996495|Ask Me Anything: Dynamic Memory Networks for Natural Language Processing |
|rezende16 | 0.8251257|One-Shot Generalization in Deep Generative Models                        |
|miao16    | 0.7024743|Neural Variational Inference for Text Processing                         |
|lie16     | 0.6826040|Learning to Generate with Memory                                         |


# topic 50
|word      |    weight|
|:---------|---------:|
|newton    | 0.0211472|
|descent   | 0.0113508|
|smooth    | 0.0113270|
|strongly  | 0.0090816|
|mini      | 0.0083985|
|gradients | 0.0080394|
|batch     | 0.0077070|
|lemma     | 0.0073936|
|zhang     | 0.0070236|
|nonconvex | 0.0069695|


|key         |    weight|title                                                                                      |
|:-----------|---------:|:------------------------------------------------------------------------------------------|
|arjevani16  | 0.9995827|On the Iteration Complexity of Oblivious First-Order Optimization Algorithms               |
|rodomanov16 | 0.9994792|A Superlinearly-Convergent Proximal Newton-type Method for the Optimization of Finite Sums |
|reddi16     | 0.9885134|Stochastic Variance Reduction for Nonconvex Optimization                                   |
|hazana16    | 0.8102349|Variance-Reduced and Projection-Free Stochastic Optimization                               |
|perolat16   | 0.7615196|Softened Approximate Policy Iteration for Markov Games                                     |


